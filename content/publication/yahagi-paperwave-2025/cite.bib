@misc{yahagi_paperwave_2025,
 abstract = {Listening to audio content, such as podcasts and audiobooks, is one way for people to engage with knowledge. Listening affords people more mobility than reading by seeing, thereby broadening their learning opportunities. This study explores the potential applications of large language models (LLMs) to adapt text documents to audio content and addresses the lack of listening-friendly materials for niche content, such as research papers. LLMs can generate scripts of audio content in various styles tailored to specific needs, such as full-content duration or speech types (monologue or dialogue). To explore this potential, we developed PaperWave as a prototype that transforms academic paper PDFs into conversational podcasts. Our two-month investigation, involving 11 participants (including the authors), employed an autobiographical design, a field study, and a design workshop. The findings highlight the importance of considering listener interaction with their environment when designing document-to-audio systems.},
 author = {Yahagi, Yuchi and Chujo, Rintaro and Harada, Yuga and Han, Changyo and Sugiyama, Kohei and Naemura, Takeshi},
 doi = {10.1145/3706599.3706664},
 file = {Preprint PDF:/Users/hanc/Zotero/storage/X8HJZ6EH/Yahagi et al. - 2025 - PaperWave Listening to Research Papers as Conversational Podcasts Scripted by LLM.pdf:application/pdf;Snapshot:/Users/hanc/Zotero/storage/WENPIXAQ/2410.html:text/html},
 keywords = {Computer Science - Human-Computer Interaction},
 month = {January},
 note = {arXiv:2410.15023 [cs]},
 shorttitle = {PaperWave},
 title = {PaperWave: Listening to Research Papers as Conversational Podcasts Scripted by LLM},
 url = {http://arxiv.org/abs/2410.15023},
 urldate = {2025-04-05},
 year = {2025}
}
